---
title: "CaRT Demonstration"
author: "JAS/jck2183"
date: "null"
output:
 output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Demonstration of Classification and Regression Trees (CaRT) using R

This demonstration of classification and regression trees (CaRT) will utilize the 2019 County Health Rankings. The rankings provide data on a number of demographic, social and environmental health characteristics for counties in the United States. We will be using this dataset to address two research questions. 

1. What are the predictors of life expectacy on a county-level?

2. Imagine a scenario where the maintainers of the CHR were concerned that the data on firearm fatalities would no longer be made public. This information has been use by a number of foundations to target population-based interventions at reducing gun violence. They are wondering if the counties with higher proportions of firearm fatalities would still be able to be identified, based on the other data within the CHR. That is, can the other data in the CHR be used to classify counties according to having higher or lower firearm_fatalities?

The first question will be addressed with a regression tree, while the second will be addressed with a classification tree.

***

### Step 1: Load needed packages

We will be using two different packages: rpart and caret. Both of these packages allow us to construct classification and regression trees, but they have different levels of functionality. Also loading tidyverse for some data wrangling and rpart.plot which makes cleaner looking plots of the trees.

```{r load_packages}
library(tidyverse)
library(rpart)
library(caret)
library(rpart.plot)
library(pROC)

```

### Step 2: Load and check data

Variable names in the original dataset were not informative, so we need to append our own as column names. We also need to strip off the Id variable for easier processing. We're also going to look at some basic descriptives of the data to determine if it needs cleaning, imputation of missing data, etc.

```{r data_prep}

chr<-read.csv("./data/chr.csv")

chr<-chr[,2:68]

var.names<-c("pre_death", "poorhealth", "poorphyshealth_days", "poormenthealth_days", "low_bwt", "ad_smoking", "ad_obesity", "foodenv_index", "phys_inactivity", "exer_access", "excess_drink", "alc_drivdeaths", "sti", "teen_birth", "uninsured", "primcareproviders", "dentists", "menthealthproviders", "prevhosp", "mammo_screen", "flu_vacc", "hsgrad", "somecollege", "unemployed", "child_poverty", "income_ineq", "sing_parent", "social_assoc", "violent_crime", "injury_deaths", "pm_air", "water_viol", "housing_prob", "driving_alone", "long_commute", "life_exp", "age_adj_premortality", "freq_physdistress", "freq_mentdistress", "diabetes", "hiv", "food_insecure", "ltd_access_healthyfood", "mvcrash_deaths", "insuff_sleep", "uninsured_adults", "uninsured_child", "other_pcp", "medhhinc", "freelunch_child", "res_seg_bw", "res_seg_nw", "firearm_fatalities", "homeownership", "hous_cost_burden", "population", "bw18", "gte65", "nonhisp_afam", "AmerInd_AlasNative", "Asian", "OPacIslander", "Hisp", "nonhisp_white", "nonprof_english", "female", "rural")

colnames(chr)<-var.names

chr$age_adj_premortality<-NULL
chr$pre_death<-NULL

#Will idenitify any rows that do not have complete cases (i.e. have missing data)
miss.rows<-chr[!complete.cases(chr),]

summary(chr)

#variables have very different distributions, but tree-based methods do not require scaling.

#Create the variable for Question 2, an indicator of having fire-arm fatalities above the median

chr$firearm.class<-as.factor(ifelse(chr$firearm_fatalities>median(chr$firearm_fatalities),1,0))
summary(chr$firearm.class)
#Data are slightly unbalanced.

```

### Step 3: Partition data into training and testing sets.

```{r}

set.seed(100)
#To address Question 1 
training.data.q1<-chr$life_exp %>% createDataPartition(p=0.7, list=F)
train.data.q1<-chr[training.data.q1, ]
test.data.q1<-chr[-training.data.q1, ]

train.data.q1$firearm.class<-NULL
test.data.q1$firearm.class<-NULL

#To address Question 2
training.data.q2<-chr$firearm.class%>% createDataPartition(p=0.7, list=F)
train.data.q2<-chr[training.data.q2, ]
test.data.q2<-chr[-training.data.q2, ]

train.data.q2$firearm_fatalities<-NULL
test.data.q2$firearm_fatalities<-NULL

```

### Step 4: PART 1: REGRESSION TREES

We will create a number of regression trees to predict life expectancy. First, we will use the default values of rpart. Then, we will vary some of the control parameters.

***
From the rpart documentation, this lists the defaults of rpart.control
rpart.control(minsplit = 20, minbucket = round(minsplit/3), cp = 0.01,
maxcompete = 4, maxsurrogate = 5, usesurrogate = 2, xval = 10,
surrogatestyle = 0, maxdepth = 30, ...)
***

Variable Importance: "An overall measure of variable importance is the sum of the goodness of split measures for each split for which it was the primary variable.""

```{r}
#Regression Tree 1-default values of rpart
tree.lifexp<-rpart(life_exp ~ ., data=train.data.q1, method="anova")
plot(tree.lifexp, uniform=TRUE)
text(tree.lifexp, use.n=TRUE, all=TRUE, cex=0.8)

printcp(tree.lifexp)
plotcp(tree.lifexp)
print(tree.lifexp)
rpart.plot(tree.lifexp)

#Regression Tree 2- varying values in rpart.control, specifically going to cp=0.001, to find minimum cv-error
tree.lifexp.2<-rpart(life_exp ~ ., data=train.data.q1, method="anova", control=rpart.control(cp=0.001))
plotcp(tree.lifexp.2)
rpart.plot(tree.lifexp.2)
printcp(tree.lifexp.2)

selected.cp<-tree.lifexp.2$cptable[which.min(tree.lifexp.2$cptable[,"xerror"]), "CP"]

tree.lifexp.pruned<-prune(tree.lifexp.2, cp=selected.cp)
rpart.plot(tree.lifexp.pruned)

#Regression Tree 3-manually setting cp to 1SD greater error than minimum value
tree.lifexp.3<-rpart(life_exp ~ ., data=train.data.q1, method="anova", control=rpart.control(cp=0.006665509))
rpart.plot(tree.lifexp.3)

print(tree.lifexp.3)

#Fit model to test data and calculate R-squared and MSE
pred.intest<-predict(tree.lifexp.3, newdata=test.data.q1)
r.square.test<-cor(test.data.q1$life_exp, pred.intest)^2
r.square.test

pred.mse<-mean((pred.intest-test.data.q1$life_exp)^2)

#Plot distribution of error (not squared error)
test<-data.frame(pred.intest-test.data.q1$life_exp)
histogram(test$pred.intest...test.data.q1.life_exp)

tree.lifexp.3$variable.importance

```

### Step 5: Compare results using caret package.

```{r}
set.seed(100)
train.control<-trainControl(method="cv", number=10)
tree.lifexp.4<-train(life_exp~ . , data=train.data.q1, method="rpart",trControl=train.control)
tree.lifexp.4$bestTune
rpart.plot(tree.lifexp.4$finalModel)

pred.intest.temp<-predict(tree.lifexp.4, newdata=test.data.q1)
r.square.test.temp<-cor(test.data.q1$life_exp, pred.intest.temp)^2
r.square.test.temp


#Specify tuneGrid so caret explores wider variety of cp-values
grid<-expand.grid(cp=seq(0.001,0.1, by=0.001))
tree.lifexp.5<-train(life_exp ~ ., data=train.data.q1, method="rpart", trControl=train.control, tuneGrid=grid)
rpart.plot(tree.lifexp.5$finalModel)

tree.lifexp.5$bestTune

grid<-expand.grid(.cp=0.002)
tree.lifexp.6<-train(life_exp ~ ., data=train.data.q1, method="rpart", trControl=train.control, tuneGrid=grid)
rpart.plot(tree.lifexp.6$finalModel)

pred.intest.2<-predict(tree.lifexp.6, newdata=test.data.q1)

r.square.test.2<-cor(test.data.q1$life_exp, pred.intest.2)^2
r.square.test.2

pred.mse.2<-mean((pred.intest.2-test.data.q1$life_exp)^2)

varImp(tree.lifexp.6)


```

### Step 6: PART 2 CLASSIFICATION TREES

```{r}
#Using caret

train.control<-trainControl(method="cv", number=10, sampling="down")
grid.2<-expand.grid(cp=seq(0.001, 0.3, by=0.01))
tree.firearm<-train(firearm.class~., data=train.data.q2, method="rpart",trControl=train.control, tuneGrid=grid.2)
tree.firearm$bestTune

grid.3<-expand.grid(cp=seq(0.0005, 0.02, by =0.001))
tree.firearm<-train(firearm.class~., data=train.data.q2, method="rpart",trControl=train.control, tuneGrid=grid.3)
tree.firearm$bestTune

tree.firearm
varImp(tree.firearm)

rpart.plot(tree.firearm$finalModel)

pred.firearm<-predict(tree.firearm, test.data.q2)
pred.firearm.prob<-predict(tree.firearm, test.data.q2, type="prob")

eval.results<-confusionMatrix(pred.firearm, test.data.q2$firearm.class, positive = "1")
print(eval.results)

analysis <- roc(response=test.data.q2$firearm.class, predictor=pred.firearm.prob[,2])
plot(1-analysis$specificities,analysis$sensitivities,type="l",
ylab="Sensitiviy",xlab="1-Specificity",col="black",lwd=2,
main = "ROC Curve for Greater Firearm Fatalities")
abline(a=0,b=1)

```

